{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mdFl1m4Ipbn",
        "outputId": "ef1b20c8-b610-4ec9-e93b-d943b307f54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pyserini==0.22.0\n",
        "!pip install faiss-cpu\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\""
      ],
      "metadata": {
        "id": "SSGV3PgUq8L2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "from pyserini.search.lucene import LuceneSearcher"
      ],
      "metadata": {
        "id": "22QIrEPwKRzN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "searcher = LuceneSearcher('/content/drive/MyDrive/indexes/sample_collection_jsonl')\n",
        "searcher.set_language('fa')\n",
        "hits = searcher.search('لات')\n",
        "\n",
        "for i in range(len(hits)):\n",
        "    print(f'{i+1:2} {hits[i].docid:4} {hits[i].score:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKy7bNCVtRNs",
        "outputId": "17570fad-ec47-453a-98ec-297c02747096"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1 s53.19 4.84050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dpr dataset creation"
      ],
      "metadata": {
        "id": "760T1oa_Fk30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/single_verse.jsonl', 'r') as f:\n",
        "  dict_data_list = []\n",
        "  for line in f:\n",
        "   data = json.loads(line)\n",
        "   dict_data_list.append(data)\n",
        "\n",
        "with open('/content/drive/MyDrive/makarem.xml', 'r', encoding=\"utf8\") as f:\n",
        "  content = f.read()\n",
        "soup= BeautifulSoup(content, 'xml')\n",
        "\n",
        "searcher = LuceneSearcher('/content/drive/MyDrive/indexes/sample_collection_jsonl')\n",
        "searcher.set_language('fa')\n",
        "\n",
        "dpr_data_list = []\n",
        "\n",
        "for qa in dict_data_list:\n",
        "  question = qa['question']\n",
        "  dpr_data = {}\n",
        "  dpr_data['dataset'] = 'Quran_QA'\n",
        "  dpr_data['question'] = qa['question']\n",
        "  dpr_data['answers'] = [qa['answers']]\n",
        "  dpr_data['positive_ctxs'] = [{'title': '' , 'text': qa['context'],\n",
        "                                'score': 1000, 'title_score':1, 'passage_id':qa['pq_id']}]\n",
        "  dpr_data['negative_ctxs'] = []\n",
        "\n",
        "  hits = searcher.search(question)\n",
        "  hard_negatives = []\n",
        "  # if len(hits)>5:\n",
        "  #   negatives_number = 5\n",
        "  # else:\n",
        "  #   negatives_number = len(hits)\n",
        "\n",
        "  for i in range(len(hits)):\n",
        "    verse_data = {}\n",
        "    # print(f'{i+1:2} {hits[i].docid:4} {hits[i].score:.5f}')\n",
        "    verse_id = hits[i].docid\n",
        "    verse_content = soup.find(id=verse_id).contents[0]\n",
        "    if qa['answers'] not in verse_content:\n",
        "      verse_data['passage_id'] = verse_id\n",
        "      verse_data['text'] = verse_content\n",
        "      verse_data['title'] = ''\n",
        "      verse_data['score'] = hits[i].score\n",
        "      verse_data['title_score'] = 0\n",
        "      hard_negatives.append(verse_data)\n",
        "\n",
        "    if len(hard_negatives) == 5:\n",
        "      break\n",
        "\n",
        "  dpr_data['hard_negative_ctxs'] = hard_negatives\n",
        "\n",
        "  dpr_data_list.append(dpr_data)\n",
        "\n",
        "  del dpr_data, hard_negatives, hits"
      ],
      "metadata": {
        "id": "vqlV4dJXYDCa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dpr_data_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O_DXIUUYAxR",
        "outputId": "14dce65c-60a8-409c-f764-45de0f14640c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2471"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "split_per = math.trunc(0.8 * len(dpr_data_list))\n",
        "\n",
        "with open('/content/drive/MyDrive/DPR_train.json', 'w') as fout:\n",
        "  json.dump(dpr_data_list[:split_per], fout)\n",
        "\n",
        "with open('/content/drive/MyDrive/DPR_dev.json', 'w') as fout:\n",
        "  json.dump(dpr_data_list[split_per:], fout)"
      ],
      "metadata": {
        "id": "tYI34P1Fn4Qh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dump_jsonl(data, output_path, append=False):\n",
        "    \"\"\"\n",
        "    Write list of objects to a JSON lines file.\n",
        "    \"\"\"\n",
        "    mode = 'a+' if append else 'w'\n",
        "    with open(output_path, mode, encoding='utf-8') as f:\n",
        "        for line in data:\n",
        "            json_record = json.dumps(line, ensure_ascii=False)\n",
        "            f.write(json_record + '\\n')\n",
        "    print('Wrote {} records to {}'.format(len(data), output_path))\n",
        "\n",
        "\n",
        "output_path = '/content/drive/MyDrive/DPR_dataset.jsonl'\n",
        "dump_jsonl(dpr_data_list, output_path)"
      ],
      "metadata": {
        "id": "2HkoVtb9m1Mf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45cc0bf-c4c6-46d6-fc3e-35a23a8e20a6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 2471 records to /content/drive/MyDrive/DPR_dataset.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x4sSk0VJRdW2"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}