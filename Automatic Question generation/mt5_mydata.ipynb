{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LJKkQgebSQ8",
        "outputId": "4ebcafe4-da2e-439e-8b74-86d7b6fb555d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q transformers datasets sentencepiece\n",
        "\n",
        "!pip uninstall -y -q transformers accelerate\n",
        "!pip install -q transformers accelerate\n",
        "\n",
        "!pip install -q rouge-score\n",
        "\n",
        "!pip install -q torchmetrics\n",
        "\n",
        "!pip install -q git+https://github.com/huggingface/accelerate\n",
        "\n",
        "!git clone -q https://github.com/huggingface/transformers.git\n",
        "!cd transformers\n",
        "!pip install  -q -e."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRZ8olDQbcuV",
        "outputId": "0bfb37aa-6de6-4e5e-9876-c2f0f816c57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name_or_path = '/content/drive/MyDrive/pquad-mt5-base/checkpoint-16432'\n",
        "# model_name_or_path = '/content/drive/MyDrive/mt5-pquad/checkpoint-4032'\n",
        "# model_name_or_path ='/content/drive/MyDrive/mt5-pquad/checkpoint-470'\n",
        "model_name_or_path ='/content/drive/MyDrive/mt5-pquad/checkpoint-3790'\n",
        "from transformers import AutoTokenizer, MT5ForConditionalGeneration\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "model = MT5ForConditionalGeneration.from_pretrained(model_name_or_path)"
      ],
      "metadata": {
        "id": "4LAvkh-tbe4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "667ce12f-adf0-48a1-a697-5c3e3ef79d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets, load_dataset\n",
        "\n",
        "data_files = {\"train\": \"/content/drive/MyDrive/train.json\", \"validation\": \"/content/drive/MyDrive/dev.json\"}\n",
        "dataset = load_dataset(\"json\", data_files=data_files)\n",
        "\n",
        "train_data = dataset['train']\n",
        "valid_data = dataset['validation']\n",
        "\n",
        "concat_dataset = concatenate_datasets([train_data, valid_data])\n",
        "dataset=concat_dataset"
      ],
      "metadata": {
        "id": "AxID_ZXDcobB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "7KcAWOW3anLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c8cd45-0b95-46d5-9ff7-95d0b9a0df14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['pq_id', 'answers', 'context', 'question'],\n",
              "    num_rows: 2088\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del concat_dataset, train_data, valid_data\n",
        "\n",
        "small_dataset = dataset\n",
        "\n",
        "# small_dataset= dataset.filter(lambda example: len(example['answers'][0]['text'])>0)\n",
        "# small_dataset= small_dataset.filter(lambda example: len(example['context'])<600)\n",
        "# small_dataset= small_dataset.filter(lambda example: 'چرا' not in example['context'])\n",
        "\n",
        "split_data = small_dataset.train_test_split(test_size=0.1, seed= 42, shuffle=True)\n",
        "\n",
        "dataset = split_data\n",
        "\n",
        "del split_data"
      ],
      "metadata": {
        "id": "t9yPMwvcanAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "99s83Te5UM3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7180649d-5890-48f8-90f5-4a994ec03ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['pq_id', 'answers', 'context', 'question'],\n",
              "        num_rows: 1879\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['pq_id', 'answers', 'context', 'question'],\n",
              "        num_rows: 209\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_dataset(example):\n",
        "  return {'input': 'answer: ' + example['answers'][0]['text'] + ' context: ' + example['context'], 'target': example['question']}\n",
        "\n",
        "\n",
        "dataset = dataset.map(format_dataset, remove_columns=dataset['train'].column_names)"
      ],
      "metadata": {
        "id": "6KtbipDEcHYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = dataset['test']\n",
        "\n",
        "test_data[0]"
      ],
      "metadata": {
        "id": "FU3_5VOLcIS7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "133fe15b-a40f-47c5-805e-260ab741f556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'answer: هر کس به دعوت کننده الهی پاسخ نگوید context:  هنگامی که گروهی از جنّ را به سوی تو متوجّه ساختیم که قرآن را بشنوند؛ وقتی حضور یافتند به یکدیگر گفتند: «خاموش باشید و بشنوید!» و هنگامی که پایان گرفت، به سوی قوم خود بازگشتند و آنها را بیم دادند! گفتند: «ای قوم ما! ما کتابی را شنیدیم که بعد از موسی نازل شده، هماهنگ با نشانه\\u200cهای کتابهای پیش از آن، که به سوی حقّ و راه راست هدایت می\\u200cکند. ای قوم ما! دعوت کننده الهی را اجابت کنید و به او ایمان آورید تا گناهانتان را ببخشد و شما را از عذابی دردناک پناه دهد! و هر کس به دعوت کننده الهی پاسخ نگوید، هرگز نمی\\u200cتواند از چنگال عذاب الهی در زمین فرار کند، و غیر از خدا یار و یاوری برای او نیست؛ چنین کسانی در گمراهی آشکارند!»',\n",
              " 'target': 'چه کسی هرگز نمی\\u200cتواند از چنگال عذاب الهی در زمین فرار کند؟'}"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_features(example_batch):\n",
        "    input_encodings = tokenizer.batch_encode_plus(example_batch['input'], truncation=True, padding='max_length', max_length=564)\n",
        "    target_encodings = tokenizer.batch_encode_plus(example_batch['target'], truncation=True, padding='max_length', max_length=64)\n",
        "\n",
        "    encodings = {\n",
        "        'input_ids': input_encodings['input_ids'],\n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'labels': target_encodings['input_ids'],\n",
        "        'decoder_attention_mask': target_encodings['attention_mask']\n",
        "    }\n",
        "\n",
        "    return encodings\n"
      ],
      "metadata": {
        "id": "zHjpWBS1cQxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(convert_to_features, batched=True, remove_columns=dataset['train'].column_names)\n",
        "\n",
        "columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
        "\n",
        "dataset.set_format(type='torch', columns=columns)"
      ],
      "metadata": {
        "id": "md8KO2XCcWBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import default_data_collator\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq,Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "# data_collator = default_data_collator\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer)"
      ],
      "metadata": {
        "id": "jKW50WNbcZ8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "# set training arguments - Feel free to adapt it\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/mt5-pquad\",\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=1,\n",
        "    per_device_eval_batch_size=4,\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_steps=8000,\n",
        "    #eval_steps=1000,\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    # push_to_hub=False\n",
        "    #fp16=True,\n",
        ")"
      ],
      "metadata": {
        "id": "Vl3r0drrccr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset['train'],\n",
        "    eval_dataset=dataset['test'],\n",
        "    # data_collator=T2TDataCollator(),\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    # compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "fvVt0hhKclKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "x1kNjEmFcpcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "iV4kCk9NdGFh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "fb8701e5-3bbc-4937-ccb3-1e577723c188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='470' max='470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [470/470 03:41, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.565944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=470, training_loss=0.19717499753262135, metrics={'train_runtime': 222.0012, 'train_samples_per_second': 8.464, 'train_steps_per_second': 2.117, 'total_flos': 1094425112125440.0, 'train_loss': 0.19717499753262135, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "prompt = \"answer: طور context: اي بني اسرائيل ما شما را از (چنگال) دشمنتان نجات داديم، و در طرف راست كوه طور با شما وعده گذارديم، و من و سلوي بر شما نازل كرديم.د\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "generated_ids = model.generate(input_ids,\n",
        "                                    num_beams=7,\n",
        "                                    num_return_sequences=7,\n",
        "#                                     top_k=10,\n",
        "#                                     top_p=.2,\n",
        "#                                     temperature=0.95,\n",
        "\n",
        "                                    max_length=200)\n",
        "for generated in generated_ids:\n",
        "    generated_text = tokenizer.decode(generated,skip_special_tokens=True)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "Eu4cky5edI75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0ba9e2-5950-47d5-dd57-b178b21f492f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "بنی اسرائيل در طرف راست چه طرفی با بنی اسرائيل وعده گذارند؟\n"
          ]
        }
      ]
    }
  ]
}