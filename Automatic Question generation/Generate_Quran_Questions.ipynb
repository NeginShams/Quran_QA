{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Yan6KXLAJqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd84521-2834-4f0d-ffb6-843244a293cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import csv\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "nPPN5GQAA6VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q transformers datasets sentencepiece\n",
        "\n",
        "!pip uninstall -y -q transformers accelerate\n",
        "!pip install -q transformers accelerate\n",
        "\n",
        "!pip install -q rouge-score\n",
        "\n",
        "!pip install -q torchmetrics\n",
        "\n",
        "!pip install -q git+https://github.com/huggingface/accelerate\n",
        "\n",
        "!git clone -q https://github.com/huggingface/transformers.git\n",
        "!cd transformers\n",
        "!pip install  -q -e."
      ],
      "metadata": {
        "id": "B7iGEQmmAS-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e960013f-47ef-454f-848a-3474c0334780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name_or_path = '/content/drive/MyDrive/mt5-pquad/checkpoint-1917'\n",
        "from transformers import AutoTokenizer, MT5ForConditionalGeneration\n",
        "tokenizer_test = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "model_test = MT5ForConditionalGeneration.from_pretrained(model_name_or_path)"
      ],
      "metadata": {
        "id": "wXcNWLuxh9hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verses = set()\n",
        "\n",
        "with open('/content/drive/MyDrive/single_verse.jsonl', 'r') as f:\n",
        "  data_list = []\n",
        "  for line in f:\n",
        "    data = json.loads(line)\n",
        "    data_list.append(data)\n",
        "\n",
        "for qa in data_list:\n",
        "  verses.add(qa['pq_id'])"
      ],
      "metadata": {
        "id": "mrMCZVOtQGCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_path = '/content/drive/MyDrive/quran_named_entities/'\n",
        "\n",
        "dict_data_list = []\n",
        "\n",
        "for each in os.listdir(ner_path):\n",
        "  file_path = '/content/drive/MyDrive/quran_named_entities/' + each\n",
        "  entity_file = open(file_path, 'r', encoding='utf-8-sig')\n",
        "  reader = csv.DictReader(entity_file)\n",
        "  entity_list = list(reader)\n",
        "  dict_data_list += entity_list\n",
        "\n",
        "# for dict_data in dict_data_list:\n",
        "#   if dict_data['verse_id'] in verses:\n",
        "#     dict_data_list.remove(dict_data)\n",
        "\n",
        "unique_verses = []\n",
        "\n",
        "input_data = []\n",
        "answer = []\n",
        "context = []\n",
        "for i in range(0, len(dict_data_list)):\n",
        "  if dict_data_list[i]['verse_id'] not in verses:\n",
        "    input_data.append('answer: ' + dict_data_list[i]['answer'].strip() + ' context: ' + dict_data_list[i]['context'])\n",
        "    answer.append(dict_data_list[i]['answer'])\n",
        "    context.append(dict_data_list[i]['context'])\n",
        "\n",
        "    unique_verses.append(dict_data_list[i])"
      ],
      "metadata": {
        "id": "af4rNIGYh-wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data[2]"
      ],
      "metadata": {
        "id": "V1nCJe5fiw9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_gen(model, tokenizer, input_text, max_length=50, do_sample=False, temperature=None, num_beams=10, top_k=None, top_p=None, early_stopping=True, num_return_sequences=1):\n",
        "               input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "               generated_ids = model.generate(input_ids, max_length=max_length, do_sample=do_sample, top_k=top_k, temperature=temperature, num_beams=num_beams)\n",
        "#generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "               return generated_ids"
      ],
      "metadata": {
        "id": "KPFfpA1FkTPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_test.to(device)\n",
        "\n",
        "# Using the custom_gen. Will have to change for our code.\n",
        "bn_pred_ques = {}\n",
        "all_generated_ids = []\n",
        "for prompt in input_data:\n",
        "    # print(prompt)\n",
        "    generated_ids = custom_gen(model_test,tokenizer_test,prompt,max_length=50,do_sample=True,top_k=40, top_p=0.95,num_return_sequences=20)\n",
        "    all_generated_ids.append(generated_ids)\n",
        "pred = []\n",
        "pred_ques =[]\n",
        "for text in all_generated_ids:\n",
        "    for generated in text:\n",
        "        generated_text = tokenizer_test.decode(generated,skip_special_tokens=True)\n",
        "#         print(generated_text)\n",
        "        pred.append(generated_text)\n",
        "        bn_pred_ques[prompt] = pred\n",
        "#     pred_ques.append(pred)\n",
        "# print(pred)\n",
        "# for generated in generated_ids:\n",
        "#     generated_text = tokenizer_test.decode(generated,skip_special_tokens=True)\n",
        "#     print(generated_text)\n",
        "#     pred.append(generated_text)\n",
        "#     bn_pred_ques[prompt] = pred"
      ],
      "metadata": {
        "id": "nZVEEzeqkX68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "CnDKxCV6kdqL",
        "outputId": "6323d8ec-4c03-46b4-9a53-b6a8fea29ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-008509a38355>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counter = 0\n",
        "# for each in pred:\n",
        "#   print(counter)\n",
        "#   print(each)\n",
        "#   print(\"*************\")\n",
        "#   counter+=1"
      ],
      "metadata": {
        "id": "Zp59VGCaxWSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FS7jz_vDyReP",
        "outputId": "8af7a673-0a47-4a92-9507-b171e5236349"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'answer: قرآن context: ما اینچنین  قرآن را به درون دلهای مجرمان راه می\\u200cدهیم!'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt0j6Lutyd-c",
        "outputId": "3c15b177-9ac0-4808-8d0f-e800e275dfea"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8436"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write to file"
      ],
      "metadata": {
        "id": "wfI3fFd8WCYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dump_jsonl(data, output_path, append=False):\n",
        "    \"\"\"\n",
        "    Write list of objects to a JSON lines file.\n",
        "    \"\"\"\n",
        "    mode = 'a+' if append else 'w'\n",
        "    with open(output_path, mode, encoding='utf-8') as f:\n",
        "        for line in data:\n",
        "            json_record = json.dumps(line, ensure_ascii=False)\n",
        "            f.write(json_record + '\\n')\n",
        "    print('Wrote {} records to {}'.format(len(data), output_path))"
      ],
      "metadata": {
        "id": "EjPT0wRLWBYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_list = []\n",
        "multiple_occurence = []\n",
        "\n",
        "for i in range(0, len(unique_verses)):\n",
        "  new_data = {}\n",
        "  answer = unique_verses[i]['answer'].strip()\n",
        "  context = unique_verses[i]['context']\n",
        "\n",
        "  new_data['context'] = context\n",
        "  new_data['pq_id'] = unique_verses[i]['verse_id']\n",
        "  new_data['question'] = pred[i]\n",
        "\n",
        "  if context.count(answer) == 1:\n",
        "    answers_list = []\n",
        "    answer_dict = {}\n",
        "    answer_dict['text'] = answer\n",
        "    answer_dict['start_char'] = context.find(answer)\n",
        "    answers_list.append(answer_dict)\n",
        "    new_data['answers'] = answers_list\n",
        "    new_data_list.append(new_data)\n",
        "\n",
        "  else:\n",
        "    new_data['answers'] = answer\n",
        "    new_data['freq'] = context.count(answer)\n",
        "    multiple_occurence.append(new_data)"
      ],
      "metadata": {
        "id": "65R0jR5zWFq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_data_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "758-yYBJds0p",
        "outputId": "5e1af3a4-af0f-4967-f23c-de2b578e526c"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3239"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/MyDrive/automatic_data.jsonl'\n",
        "dump_jsonl(new_data_list, output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQaUCXj2dmqf",
        "outputId": "04960330-2110-4a68-fe4d-b58b5b517ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote 3239 records to /content/drive/MyDrive/automatic_data.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(multiple_occurence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaLwE-T6ynrk",
        "outputId": "a682c6b9-8c91-4871-a9ab-3c3f8704b1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5197"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/MyDrive/automatic_multiple_occurence.jsonl'\n",
        "dump_jsonl(multiple_occurence, output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCrKnFD2y2qg",
        "outputId": "49aedd22-0bde-46b8-ccc2-a1c35f174995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 5197 records to /content/drive/MyDrive/automatic_multiple_occurence.jsonl\n"
          ]
        }
      ]
    }
  ]
}