{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3e588c333254e86a287a2102c1af3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ccda6c0e7d64df3aefdf172a486c8b5",
              "IPY_MODEL_b90920cc53fe4d76b148b2bbd7dba665",
              "IPY_MODEL_7344b247f6f349c782ca83511d58e032"
            ],
            "layout": "IPY_MODEL_7ca14f757ebd4dceb1c4c954157671c0"
          }
        },
        "8ccda6c0e7d64df3aefdf172a486c8b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd7d084b473142f7866ec7ad144d41db",
            "placeholder": "​",
            "style": "IPY_MODEL_faadd39a96914d5f9a723031ce227dc4",
            "value": "Generating train split: "
          }
        },
        "b90920cc53fe4d76b148b2bbd7dba665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfd79a160f204c42937a7a3f89942a33",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f38472ce69094c969182e09d2284cf14",
            "value": 1
          }
        },
        "7344b247f6f349c782ca83511d58e032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb918d9f92d46f094276579157f36f3",
            "placeholder": "​",
            "style": "IPY_MODEL_b7cfdc0e38134d209691ee006b84a0a1",
            "value": " 656/0 [00:00&lt;00:00, 2021.90 examples/s]"
          }
        },
        "7ca14f757ebd4dceb1c4c954157671c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd7d084b473142f7866ec7ad144d41db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faadd39a96914d5f9a723031ce227dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfd79a160f204c42937a7a3f89942a33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f38472ce69094c969182e09d2284cf14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fb918d9f92d46f094276579157f36f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7cfdc0e38134d209691ee006b84a0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0da21ebc1a2346459fd863711df6e2a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc5a78b33d8a4898b9e05b816dccf3ad",
              "IPY_MODEL_d52d803e6d844a44af9dbe60eee06517",
              "IPY_MODEL_d01a454037d74ef6a48c455eaebec2eb"
            ],
            "layout": "IPY_MODEL_61e8480191cb4159b2331341848b2d03"
          }
        },
        "dc5a78b33d8a4898b9e05b816dccf3ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05a213f4e85c4b638eb3855c9139a571",
            "placeholder": "​",
            "style": "IPY_MODEL_b990a4a74a0544828e16dc1a1d51615e",
            "value": "Generating validation split: "
          }
        },
        "d52d803e6d844a44af9dbe60eee06517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_508723c828ce4840af74801bc247310e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22b766ea62b9488493bc785bd4785e5b",
            "value": 1
          }
        },
        "d01a454037d74ef6a48c455eaebec2eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de2a74b39b3c4b83b06723184790bfbd",
            "placeholder": "​",
            "style": "IPY_MODEL_fdb95e3a45454a6389b2751d5e6033b3",
            "value": " 164/0 [00:00&lt;00:00, 1866.18 examples/s]"
          }
        },
        "61e8480191cb4159b2331341848b2d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a213f4e85c4b638eb3855c9139a571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b990a4a74a0544828e16dc1a1d51615e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "508723c828ce4840af74801bc247310e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "22b766ea62b9488493bc785bd4785e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de2a74b39b3c4b83b06723184790bfbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb95e3a45454a6389b2751d5e6033b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJ3v79snJ_Rj"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import string\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OWH0IVALKHPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511a205d-340b-4a83-de65-1092401bebdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets sentencepiece\n",
        "\n",
        "!pip uninstall -y -q transformers accelerate\n",
        "!pip install -q transformers accelerate\n",
        "\n",
        "!pip install -q evaluate\n",
        "\n",
        "!pip install -q git+https://github.com/huggingface/accelerate\n",
        "\n",
        "!git clone https://github.com/huggingface/transformers.git\n",
        "!cd transformers\n",
        "!pip install -e.\n",
        "\n",
        "!pip install -q parsivar"
      ],
      "metadata": {
        "id": "o2sa8CxMKTKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b315e18c-d44a-49e0-848e-f607f23b97e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 191825, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# data_files = {\"train\": \"/content/drive/MyDrive/train.json\", \"validation\": \"/content/drive/MyDrive/dev.json\"}\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/extra_translations/ansarian/ansarian_train.json\"\n",
        "valdiation_path = \"/content/drive/MyDrive/extra_translations/ansarian/ansarian_dev.json\"\n",
        "\n",
        "data_files = {\"train\": train_path, \"validation\": valdiation_path}\n",
        "dataset = load_dataset(\"json\", data_files=data_files)"
      ],
      "metadata": {
        "id": "kVxJs45zKKLC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "c3e588c333254e86a287a2102c1af3e1",
            "8ccda6c0e7d64df3aefdf172a486c8b5",
            "b90920cc53fe4d76b148b2bbd7dba665",
            "7344b247f6f349c782ca83511d58e032",
            "7ca14f757ebd4dceb1c4c954157671c0",
            "fd7d084b473142f7866ec7ad144d41db",
            "faadd39a96914d5f9a723031ce227dc4",
            "cfd79a160f204c42937a7a3f89942a33",
            "f38472ce69094c969182e09d2284cf14",
            "3fb918d9f92d46f094276579157f36f3",
            "b7cfdc0e38134d209691ee006b84a0a1",
            "0da21ebc1a2346459fd863711df6e2a2",
            "dc5a78b33d8a4898b9e05b816dccf3ad",
            "d52d803e6d844a44af9dbe60eee06517",
            "d01a454037d74ef6a48c455eaebec2eb",
            "61e8480191cb4159b2331341848b2d03",
            "05a213f4e85c4b638eb3855c9139a571",
            "b990a4a74a0544828e16dc1a1d51615e",
            "508723c828ce4840af74801bc247310e",
            "22b766ea62b9488493bc785bd4785e5b",
            "de2a74b39b3c4b83b06723184790bfbd",
            "fdb95e3a45454a6389b2751d5e6033b3"
          ]
        },
        "outputId": "0f6f8313-deb3-42b8-ae56-ba76c454c258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3e588c333254e86a287a2102c1af3e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0da21ebc1a2346459fd863711df6e2a2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 384\n",
        "stride = 128\n",
        "\n",
        "def preprocess_validation_examples(examples, tokenizer):\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    inputs = tokenizer(\n",
        "        questions,\n",
        "        examples[\"context\"],\n",
        "        max_length=max_length,\n",
        "        truncation=\"only_second\",\n",
        "        stride=stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
        "    example_ids = []\n",
        "\n",
        "    for i in range(len(inputs[\"input_ids\"])):\n",
        "        sample_idx = sample_map[i]\n",
        "        example_ids.append(examples[\"pq_id\"][sample_idx])\n",
        "\n",
        "        sequence_ids = inputs.sequence_ids(i)\n",
        "        offset = inputs[\"offset_mapping\"][i]\n",
        "        inputs[\"offset_mapping\"][i] = [\n",
        "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
        "        ]\n",
        "\n",
        "    inputs[\"example_id\"] = example_ids\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "BGFoxXSaKSef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q parsivar"
      ],
      "metadata": {
        "id": "sD1Oeve9RfPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ec993d-d6f5-4d6b-e74b-9d038382b369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting parsivar\n",
            "  Downloading parsivar-0.2.3.1-py3-none-any.whl (18.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from parsivar) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->parsivar) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->parsivar) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->parsivar) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.6->parsivar) (4.66.2)\n",
            "Installing collected packages: parsivar\n",
            "Successfully installed parsivar-0.2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from parsivar import Normalizer\n",
        "\n",
        "my_normalizer = Normalizer()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open('/content/drive/MyDrive/extra_translations/ansarian/ansarian_dev.json', 'r') as f:\n",
        "  dev_data_list = json.load(f)\n",
        "\n",
        "predicted_output = []\n",
        "ground_truth = []\n",
        "\n",
        "for qa in dev_data_list[:100]:\n",
        "  # ground_truth.append(qa['answers'][0]['text'])\n",
        "  ground_truth.append(my_normalizer.normalize(qa['answers'][0]['text']))\n",
        "\n",
        "  # Use the model to answer the question\n",
        "  result = model(question=qa['question'], context=qa['context'])\n",
        "\n",
        "  answer = result[\"answer\"]\n",
        "\n",
        "  predicted_output.append(my_normalizer.normalize(answer))\n"
      ],
      "metadata": {
        "id": "mGZU894nKtJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "checkpoint1 = '/content/drive/MyDrive/parsbert_pquad/checkpoint-8000'\n",
        "checkpoint2 = '/content/drive/MyDrive/albert_pquad/checkpoint-8000'\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "tokenizer1 = AutoTokenizer.from_pretrained(checkpoint1)\n",
        "model1 = AutoModelForQuestionAnswering.from_pretrained(checkpoint1).to(device)\n",
        "\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(checkpoint2)\n",
        "model2 = AutoModelForQuestionAnswering.from_pretrained(checkpoint2).to(device)\n"
      ],
      "metadata": {
        "id": "t0AWhD79RdpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from parsivar import Normalizer\n",
        "\n",
        "my_normalizer = Normalizer()\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "def compute_answer(checkpoint_list, data_path = '/content/drive/MyDrive/extra_translations/ansarian/ansarian_dev.json'):\n",
        "\n",
        "  with open(data_path, 'r') as f:\n",
        "    dev_data_list = json.load(f)\n",
        "\n",
        "  models_results = []\n",
        "  theoretical_answers = []\n",
        "\n",
        "  for checkpoint in checkpoint_list:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(checkpoint).to(device)\n",
        "\n",
        "    predicted_outputs = []\n",
        "\n",
        "    for qa in dev_data_list:\n",
        "      question = qa['question']\n",
        "      context = qa['context']\n",
        "\n",
        "      inputs = tokenizer(question, context, return_tensors='pt')\n",
        "\n",
        "      with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "      start_logits = outputs.start_logits\n",
        "      end_logits = outputs.end_logits\n",
        "\n",
        "      start_probs = torch.nn.functional.softmax(start_logits, dim=1)\n",
        "      end_probs = torch.nn.functional.softmax(end_logits, dim=1)\n",
        "\n",
        "      # Find spans with highest probabilities\n",
        "      n_best = 20\n",
        "      max_answer_length = 30\n",
        "      try:\n",
        "        start_prob, start_index = torch.topk(start_probs, n_best, dim=1)  # Top 5 start positions\n",
        "        end_prob, end_index = torch.topk(end_probs, n_best, dim=1)  # Top 5 end positions\n",
        "      except:\n",
        "        n_best = 15\n",
        "\n",
        "      answers_dict = {}\n",
        "      # Extract text spans\n",
        "      for i in range(n_best):\n",
        "          start_pos = start_index[0][i]\n",
        "          end_pos = end_index[0][i]\n",
        "          if end_pos < start_pos or end_pos - start_pos > max_answer_length:\n",
        "              continue\n",
        "          answer_tokens = inputs['input_ids'][0][start_pos: end_pos+1]\n",
        "          answer = tokenizer.decode(answer_tokens)\n",
        "          if answer and answer != '[CLS]' and answer != '[SEP]' and answer in context and len(answer) <= 30 and len(answer)>0:\n",
        "            answers_dict[answer] = start_prob[0][i].item()\n",
        "\n",
        "      try:\n",
        "        final_answer = max(answers_dict, key=answers_dict.get)\n",
        "        predicted_outputs.append({\"id\": qa['pq_id'], \"prediction_text\": my_normalizer.normalize(final_answer).strip(), \"score\": answers_dict[final_answer]})\n",
        "      except:\n",
        "        final_answer = ''\n",
        "        predicted_outputs.append({\"id\": qa['pq_id'], \"prediction_text\": my_normalizer.normalize(final_answer).strip(), \"score\": 0})\n",
        "\n",
        "    models_results.append(predicted_outputs)\n",
        "\n",
        "  predicted_answers = []\n",
        "\n",
        "  for i in range(len(dev_data_list)):\n",
        "    max = 0\n",
        "    answer = ''\n",
        "    for result in models_results:\n",
        "      if result[i]['score'] > max:\n",
        "        max = result[i]['score']\n",
        "        answer = result[i]['prediction_text']\n",
        "\n",
        "    predicted_answers.append({\"id\": dev_data_list[i]['pq_id'], \"prediction_text\": answer})\n",
        "\n",
        "\n",
        "  # print(predicted_answers)\n",
        "\n",
        "\n",
        "  for qa in dev_data_list:\n",
        "    new_ex = {}\n",
        "    new_ex['id'] = qa[\"pq_id\"]\n",
        "    new_ex['answers'] = {}\n",
        "    new_ex['answers']['answer_start'] = [qa['answers'][0]['start_char']]\n",
        "    # new_ex['answers']['text'] = [qa['answers'][0]['text']]\n",
        "    new_ex['answers']['text'] = [my_normalizer.normalize(qa['answers'][0]['text'])]\n",
        "    theoretical_answers.append(new_ex)\n",
        "\n",
        "\n",
        "  return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
      ],
      "metadata": {
        "id": "REYe4O9AxSql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"squad\")\n",
        "\n",
        "checkpoints = ['/content/drive/MyDrive/albert_pquad/checkpoint-8000',\n",
        "               '/content/drive/MyDrive/parsbert_pquad/checkpoint-8000']\n",
        "\n",
        "compute_answer(checkpoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wrs7Aq6YguJ",
        "outputId": "5a497626-1d14-46b7-90ba-6574a4550384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'id': 's2.283', 'prediction_text': ''}, {'id': 's2.34', 'prediction_text': ''}, {'id': 's2.36', 'prediction_text': ''}, {'id': 's7.22', 'prediction_text': ''}, {'id': 's7.20', 'prediction_text': ''}, {'id': 's6.161', 'prediction_text': ''}, {'id': 's41.15', 'prediction_text': ''}, {'id': 's46.21', 'prediction_text': ''}, {'id': 's46.21', 'prediction_text': ''}, {'id': 's51.38', 'prediction_text': ''}, {'id': 's51.38', 'prediction_text': ''}, {'id': 's54.22', 'prediction_text': ''}, {'id': 's54.18', 'prediction_text': ''}, {'id': 's69.6', 'prediction_text': ''}, {'id': 's69.5', 'prediction_text': ''}, {'id': 's73.18', 'prediction_text': ''}, {'id': 's73.17', 'prediction_text': ''}, {'id': 's73.16', 'prediction_text': ''}, {'id': 's33.33', 'prediction_text': ''}, {'id': 's33.53', 'prediction_text': ''}, {'id': 's33.56', 'prediction_text': ''}, {'id': 's2.153', 'prediction_text': ''}, {'id': 's2.151', 'prediction_text': ''}, {'id': 's3.32', 'prediction_text': ''}, {'id': 's3.164', 'prediction_text': ''}, {'id': 's3.164', 'prediction_text': ''}, {'id': 's4.12', 'prediction_text': ''}, {'id': 's4.12', 'prediction_text': ''}, {'id': 's4.58', 'prediction_text': ''}, {'id': 's4.58', 'prediction_text': ''}, {'id': 's4.59', 'prediction_text': ''}, {'id': 's4.64', 'prediction_text': ''}, {'id': 's4.83', 'prediction_text': ''}, {'id': 's5.93', 'prediction_text': ''}, {'id': 's8.20', 'prediction_text': ''}, {'id': 's8.24', 'prediction_text': ''}, {'id': 's9.71', 'prediction_text': ''}, {'id': 's24.46', 'prediction_text': ''}, {'id': 's24.52', 'prediction_text': ''}, {'id': 's24.50', 'prediction_text': ''}, {'id': 's24.62', 'prediction_text': ''}, {'id': 's33.37', 'prediction_text': ''}, {'id': 's47.36', 'prediction_text': ''}, {'id': 's48.17', 'prediction_text': ''}, {'id': 's49.8', 'prediction_text': ''}, {'id': 's49.7', 'prediction_text': ''}, {'id': 's58.13', 'prediction_text': ''}, {'id': 's58.13', 'prediction_text': ''}, {'id': 's59.6', 'prediction_text': ''}, {'id': 's64.11', 'prediction_text': ''}, {'id': 's2.256', 'prediction_text': ''}, {'id': 's10.108', 'prediction_text': ''}, {'id': 's10.108', 'prediction_text': ''}, {'id': 's17.12', 'prediction_text': ''}, {'id': 's18.31', 'prediction_text': ''}, {'id': 's18.31', 'prediction_text': ''}, {'id': 's5.46', 'prediction_text': ''}, {'id': 's2.55', 'prediction_text': ''}, {'id': 's2.57', 'prediction_text': ''}, {'id': 's3.169', 'prediction_text': ''}, {'id': 's7.148', 'prediction_text': ''}, {'id': 's38.34', 'prediction_text': ''}, {'id': 's38.34', 'prediction_text': ''}, {'id': 's38.34', 'prediction_text': ''}, {'id': 's28.8', 'prediction_text': ''}, {'id': 's28.9', 'prediction_text': ''}, {'id': 's57.12', 'prediction_text': ''}, {'id': 's57.13', 'prediction_text': ''}, {'id': 's57.13', 'prediction_text': ''}, {'id': 's57.13', 'prediction_text': ''}, {'id': 's57.12', 'prediction_text': ''}, {'id': 's11.65', 'prediction_text': ''}, {'id': 's74.30', 'prediction_text': ''}, {'id': 's74.31', 'prediction_text': ''}, {'id': 's7.150', 'prediction_text': ''}, {'id': 's7.150', 'prediction_text': ''}, {'id': 's7.150', 'prediction_text': ''}, {'id': 's7.161', 'prediction_text': ''}, {'id': 's7.161', 'prediction_text': ''}, {'id': 's7.162', 'prediction_text': ''}, {'id': 's26.17', 'prediction_text': ''}, {'id': 's26.16', 'prediction_text': ''}, {'id': 's48.12', 'prediction_text': ''}, {'id': 's52.28', 'prediction_text': ''}, {'id': 's7.134', 'prediction_text': ''}, {'id': 's2.26', 'prediction_text': ''}, {'id': 's2.263', 'prediction_text': ''}, {'id': 's2.261', 'prediction_text': ''}, {'id': 's2.182', 'prediction_text': ''}, {'id': 's2.180', 'prediction_text': ''}, {'id': 's11.70', 'prediction_text': ''}, {'id': 's11.69', 'prediction_text': ''}, {'id': 's2.221', 'prediction_text': ''}, {'id': 's4.84', 'prediction_text': ''}, {'id': 's4.84', 'prediction_text': ''}, {'id': 's4.97', 'prediction_text': ''}, {'id': 's4.100', 'prediction_text': ''}, {'id': 's4.140', 'prediction_text': ''}, {'id': 's5.98', 'prediction_text': ''}, {'id': 's5.96', 'prediction_text': ''}, {'id': 's8.53', 'prediction_text': ''}, {'id': 's8.50', 'prediction_text': ''}, {'id': 's8.52', 'prediction_text': ''}, {'id': 's46.12', 'prediction_text': ''}, {'id': 's54.37', 'prediction_text': ''}, {'id': 's25.31', 'prediction_text': ''}, {'id': 's25.32', 'prediction_text': ''}, {'id': 's25.32', 'prediction_text': ''}, {'id': 's25.30', 'prediction_text': ''}, {'id': 's29.47', 'prediction_text': ''}, {'id': 's32.7', 'prediction_text': ''}, {'id': 's32.7', 'prediction_text': ''}, {'id': 's34.7', 'prediction_text': ''}, {'id': 's34.8', 'prediction_text': ''}, {'id': 's35.34', 'prediction_text': ''}, {'id': 's35.30', 'prediction_text': ''}, {'id': 's35.32', 'prediction_text': ''}, {'id': 's35.33', 'prediction_text': ''}, {'id': 's35.33', 'prediction_text': ''}, {'id': 's35.33', 'prediction_text': ''}, {'id': 's38.72', 'prediction_text': ''}, {'id': 's38.78', 'prediction_text': ''}, {'id': 's38.86', 'prediction_text': ''}, {'id': 's39.23', 'prediction_text': ''}, {'id': 's39.24', 'prediction_text': ''}, {'id': 's39.26', 'prediction_text': ''}, {'id': 's39.26', 'prediction_text': ''}, {'id': 's39.61', 'prediction_text': ''}, {'id': 's42.5', 'prediction_text': ''}, {'id': 's24.3', 'prediction_text': ''}, {'id': 's12.103', 'prediction_text': ''}, {'id': 's13.2', 'prediction_text': ''}, {'id': 's13.4', 'prediction_text': ''}, {'id': 's4.105', 'prediction_text': ''}, {'id': 's4.135', 'prediction_text': ''}, {'id': 's4.140', 'prediction_text': ''}, {'id': 's4.142', 'prediction_text': ''}, {'id': 's4.143', 'prediction_text': ''}, {'id': 's25.47', 'prediction_text': ''}, {'id': 's40.64', 'prediction_text': ''}, {'id': 's40.64', 'prediction_text': ''}, {'id': 's40.64', 'prediction_text': ''}, {'id': 's78.10', 'prediction_text': ''}, {'id': 's78.11', 'prediction_text': ''}, {'id': 's78.12', 'prediction_text': ''}, {'id': 's27.86', 'prediction_text': ''}, {'id': 's27.86', 'prediction_text': ''}, {'id': 's27.88', 'prediction_text': ''}, {'id': 's33.6', 'prediction_text': ''}, {'id': 's51.46', 'prediction_text': ''}, {'id': 's51.40', 'prediction_text': ''}, {'id': 's12.42', 'prediction_text': ''}, {'id': 's52.18', 'prediction_text': ''}, {'id': 's18.54', 'prediction_text': ''}, {'id': 's18.56', 'prediction_text': ''}, {'id': 's30.58', 'prediction_text': ''}, {'id': 's30.60', 'prediction_text': ''}, {'id': 's17.8', 'prediction_text': ''}, {'id': 's54.8', 'prediction_text': ''}, {'id': 's75.14', 'prediction_text': ''}, {'id': 's75.9', 'prediction_text': ''}, {'id': 's19.16', 'prediction_text': ''}, {'id': 's21.33', 'prediction_text': ''}, {'id': 's43.51', 'prediction_text': ''}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact_match': 0.0, 'f1': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBmgUFfke_QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZ4bsj_ie_Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1qcQhRXbe_JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from parsivar import Normalizer\n",
        "\n",
        "my_normalizer = Normalizer()\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "# def compute_answer(checkpoint_list, data_path = '/content/drive/MyDrive/extra_translations/ansarian/ansarian_dev.json'):\n",
        "\n",
        "data_path = '/content/drive/MyDrive/extra_translations/ansarian/ansarian_dev.json'\n",
        "\n",
        "checkpoint_list = ['/content/drive/MyDrive/albert_pquad/checkpoint-8000',\n",
        "               '/content/drive/MyDrive/parsbert_pquad/checkpoint-8000']\n",
        "\n",
        "\n",
        "with open(data_path, 'r') as f:\n",
        "  dev_data_list = json.load(f)\n",
        "\n",
        "models_results = []\n",
        "theoretical_answers = []\n",
        "\n",
        "for checkpoint in checkpoint_list:\n",
        "  tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "  model = AutoModelForQuestionAnswering.from_pretrained(checkpoint).to(device)\n",
        "\n",
        "  predicted_outputs = []\n",
        "\n",
        "  for qa in dev_data_list:\n",
        "    question = qa['question']\n",
        "    context = qa['context']\n",
        "\n",
        "    inputs = tokenizer(question, context, return_tensors='pt')\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(**inputs)\n",
        "\n",
        "    start_logits = outputs.start_logits\n",
        "    end_logits = outputs.end_logits\n",
        "\n",
        "    start_probs = torch.nn.functional.softmax(start_logits, dim=1)\n",
        "    end_probs = torch.nn.functional.softmax(end_logits, dim=1)\n",
        "\n",
        "    # Find spans with highest probabilities\n",
        "    n_best = 20\n",
        "    max_answer_length = 30\n",
        "    try:\n",
        "      start_prob, start_index = torch.topk(start_probs, n_best, dim=1)  # Top 5 start positions\n",
        "      end_prob, end_index = torch.topk(end_probs, n_best, dim=1)  # Top 5 end positions\n",
        "    except:\n",
        "      n_best = 15\n",
        "\n",
        "    answers_dict = {}\n",
        "    # Extract text spans\n",
        "    for i in range(n_best):\n",
        "        start_pos = start_index[0][i]\n",
        "        end_pos = end_index[0][i]\n",
        "        if end_pos < start_pos or end_pos - start_pos > max_answer_length:\n",
        "            continue\n",
        "        answer_tokens = inputs['input_ids'][0][start_pos: end_pos+1]\n",
        "        answer = tokenizer.decode(answer_tokens)\n",
        "        if answer and answer != '[CLS]' and answer != '[SEP]' and answer in context and len(answer) <= 30 and len(answer)>0:\n",
        "          answers_dict[answer] = start_prob[0][i].item()\n",
        "\n",
        "    try:\n",
        "      final_answer = max(answers_dict, key=answers_dict.get)\n",
        "      predicted_outputs.append({\"id\": qa['pq_id'], \"prediction_text\": my_normalizer.normalize(final_answer).strip(), \"score\": answers_dict[final_answer]})\n",
        "    except:\n",
        "      final_answer = ''\n",
        "      predicted_outputs.append({\"id\": qa['pq_id'], \"prediction_text\": my_normalizer.normalize(final_answer).strip(), \"score\": 0})\n",
        "\n",
        "  models_results.append(predicted_outputs)\n",
        "\n",
        "predicted_answers = []\n",
        "\n",
        "for i in range(len(dev_data_list)):\n",
        "  max = 0\n",
        "  answer = ''\n",
        "  for result in models_results:\n",
        "    if result[i]['score'] > max:\n",
        "      max = result[i]['score']\n",
        "      answer = result[i]['prediction_text']\n",
        "\n",
        "  predicted_answers.append({\"id\": dev_data_list[i]['pq_id'], \"prediction_text\": answer})\n",
        "\n",
        "\n",
        "# print(predicted_answers)\n",
        "\n",
        "\n",
        "for qa in dev_data_list:\n",
        "  new_ex = {}\n",
        "  new_ex['id'] = qa[\"pq_id\"]\n",
        "  new_ex['answers'] = {}\n",
        "  new_ex['answers']['answer_start'] = [qa['answers'][0]['start_char']]\n",
        "  # new_ex['answers']['text'] = [qa['answers'][0]['text']]\n",
        "  new_ex['answers']['text'] = [my_normalizer.normalize(qa['answers'][0]['text'])]\n",
        "  theoretical_answers.append(new_ex)\n",
        "\n",
        "\n",
        "metric.compute(predictions=predicted_answers, references=theoretical_answers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFaIJos3YgrS",
        "outputId": "fc3951d2-a061-4328-bbd1-5a3586cdc018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact_match': 49.390243902439025, 'f1': 60.497483546264014}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TDN5miI1YgmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from parsivar import Normalizer\n",
        "\n",
        "my_normalizer = Normalizer()\n",
        "\n",
        "with open('/content/drive/MyDrive/extra_translations/ansarian/ansarian_dev.json', 'r') as f:\n",
        "  dev_data_list = json.load(f)\n",
        "\n",
        "predicted_answers = []\n",
        "theoretical_answers = []\n",
        "\n",
        "for qa in dev_data_list:\n",
        "\n",
        "  ground_truth.append(my_normalizer.normalize(qa['answers'][0]['text']))\n",
        "  # ground_truth.append(qa['answers'][0]['text'])\n",
        "\n",
        "  question = qa['question']\n",
        "  context = qa['context']\n",
        "\n",
        "  inputs1 = tokenizer1(question, context, return_tensors='pt')\n",
        "  inputs2 = tokenizer2(question, context, return_tensors='pt')\n",
        "\n",
        "  # Get model output\n",
        "  with torch.no_grad():\n",
        "    outputs1 = model1(**inputs1)\n",
        "    outputs2 = model2(**inputs2)\n",
        "\n",
        "  start_logits1 = outputs1.start_logits\n",
        "  end_logits1 = outputs1.end_logits\n",
        "\n",
        "  start_logits2 = outputs2.start_logits\n",
        "  end_logits2 = outputs2.end_logits\n",
        "\n",
        "  # Apply softmax\n",
        "  start_probs1 = torch.nn.functional.softmax(start_logits1, dim=1)\n",
        "  end_probs1 = torch.nn.functional.softmax(end_logits1, dim=1)\n",
        "\n",
        "  start_probs2 = torch.nn.functional.softmax(start_logits2, dim=1)\n",
        "  end_probs2 = torch.nn.functional.softmax(end_logits2, dim=1)\n",
        "\n",
        "  # Find spans with highest probabilities\n",
        "  n_best = 20\n",
        "  max_answer_length = 30\n",
        "  try:\n",
        "    start_prob1, start_index1 = torch.topk(start_probs, n_best, dim=1)  # Top 5 start positions\n",
        "    end_prob1, end_index1 = torch.topk(end_probs, n_best, dim=1)  # Top 5 end positions\n",
        "\n",
        "    start_prob, start_index = torch.topk(start_probs, n_best, dim=1)  # Top 5 start positions\n",
        "    end_prob, end_index = torch.topk(end_probs, n_best, dim=1)  # Top 5 end positions\n",
        "  except:\n",
        "    n_best = 15\n",
        "\n",
        "  answers_dict = {}\n",
        "  # Extract text spans\n",
        "  for i in range(n_best):\n",
        "      start_pos = start_index[0][i]\n",
        "      end_pos = end_index[0][i]\n",
        "      if end_pos < start_pos or end_pos - start_pos > max_answer_length:\n",
        "          continue\n",
        "      answer_tokens = inputs['input_ids'][0][start_pos: end_pos+1]\n",
        "      answer = tokenizer.decode(answer_tokens)\n",
        "      if answer and answer != '[CLS]' and answer != '[SEP]' and answer in context and len(answer) <= 30 and len(answer)>0:\n",
        "        answers_dict[answer] = start_prob[0][i].item()\n",
        "\n",
        "  try:\n",
        "    final_answer = max(answers_dict, key=answers_dict.get)\n",
        "  except:\n",
        "    final_answer = ''\n",
        "  predicted_answers.append({\"id\": qa['pq_id'], \"prediction_text\": final_answer})\n",
        "  # predicted_answers.append({\"id\": qa['pq_id'], \"prediction_text\": my_normalizer.normalize(final_answer).strip()})\n",
        "  predicted_output.append(my_normalizer.normalize(final_answer).strip())\n",
        "\n",
        "\n",
        "\n",
        "  new_ex = {}\n",
        "  new_ex['id'] = qa[\"pq_id\"]\n",
        "  new_ex['answers'] = {}\n",
        "  new_ex['answers']['answer_start'] = [qa['answers'][0]['start_char']]\n",
        "  new_ex['answers']['text'] = [qa['answers'][0]['text']]\n",
        "  # new_ex['answers']['text'] = [my_normalizer.normalize(qa['answers'][0]['text'])]\n",
        "  theoretical_answers.append(new_ex)\n",
        "  # print(final_answer)\n",
        "  # print(\"***********************\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PBjPL0nSrsx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from parsivar import Normalizer\n",
        "\n",
        "my_normalizer = Normalizer()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open('/content/drive/MyDrive/extra_translations/ansarian/ansarian_dev.json', 'r') as f:\n",
        "  dev_data_list = json.load(f)\n",
        "\n",
        "predicted_output = []\n",
        "ground_truth = []\n",
        "\n",
        "for qa in dev_data_list[:100]:\n",
        "  # ground_truth.append(qa['answers'][0]['text'])\n",
        "  ground_truth.append(my_normalizer.normalize(qa['answers'][0]['text']))\n",
        "\n",
        "  # Use the model to answer the question\n",
        "  result = model(question=qa['question'], context=qa['context'])\n",
        "\n",
        "  answer = result[\"answer\"]\n",
        "\n",
        "  predicted_output.append(my_normalizer.normalize(answer))\n"
      ],
      "metadata": {
        "id": "FwA6Nbyt-y1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJgEGJnEgQrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X_G-9dnigQoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zSzpycGHgQkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "from parsivar import Normalizer\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/parsbert_pquad/checkpoint-8000\")\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"/content/drive/MyDrive/parsbert_pquad/checkpoint-8000\").to(device)\n",
        "my_normalizer = Normalizer()\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/extra_translations/ansarian/ansarian_dev.json', 'r') as f:\n",
        "  dev_data_list = json.load(f)\n",
        "\n",
        "predicted_output = []\n",
        "ground_truth = []\n",
        "\n",
        "predicted_answers = []\n",
        "theoretical_answers = []\n",
        "\n",
        "for qa in dev_data_list:\n",
        "\n",
        "  ground_truth.append(my_normalizer.normalize(qa['answers'][0]['text']))\n",
        "  # ground_truth.append(qa['answers'][0]['text'])\n",
        "\n",
        "  question = qa['question']\n",
        "  context = qa['context']\n",
        "\n",
        "  inputs = tokenizer(question, context, return_tensors='pt')\n",
        "\n",
        "  # Get model output\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "  start_logits = outputs.start_logits\n",
        "  end_logits = outputs.end_logits\n",
        "\n",
        "  # Apply softmax\n",
        "  start_probs = torch.nn.functional.softmax(start_logits, dim=1)\n",
        "  end_probs = torch.nn.functional.softmax(end_logits, dim=1)\n",
        "  # print(start_probs)\n",
        "  # print(len(start_probs[0]))\n",
        "  # break\n",
        "\n",
        "  # Find spans with highest probabilities\n",
        "  n_best = 20\n",
        "  max_answer_length = 30\n",
        "  try:\n",
        "    start_prob, start_index = torch.topk(start_probs, n_best, dim=1)  # Top 5 start positions\n",
        "    end_prob, end_index = torch.topk(end_probs, n_best, dim=1)  # Top 5 end positions\n",
        "  except:\n",
        "    n_best = 15\n",
        "  # print(start_prob)\n",
        "  # print(start_index)\n",
        "  # print(start_prob[0][1].item())\n",
        "  # break\n",
        "\n",
        "  answers_dict = {}\n",
        "  # Extract text spans\n",
        "  for i in range(n_best):\n",
        "      start_pos = start_index[0][i]\n",
        "      end_pos = end_index[0][i]\n",
        "      if end_pos < start_pos or end_pos - start_pos > max_answer_length:\n",
        "          continue\n",
        "      answer_tokens = inputs['input_ids'][0][start_pos: end_pos+1]\n",
        "      # answer_tokens = tokenizer.convert_ids_to_tokens(answer_tokens, skip_special_tokens=True)\n",
        "      # answer = tokenizer.decode(tokenizer.convert_tokens_to_string(answer_tokens))\n",
        "      answer = tokenizer.decode(answer_tokens)\n",
        "      if answer and answer != '[CLS]' and answer != '[SEP]' and answer in context and len(answer) <= 30 and len(answer)>0:\n",
        "        answers_dict[answer] = start_prob[0][i].item()\n",
        "\n",
        "      # print(f\"Answer {i+1}: {answer}\")\n",
        "  try:\n",
        "    final_answer = max(answers_dict, key=answers_dict.get)\n",
        "  except:\n",
        "    final_answer = ''\n",
        "  # predicted_answers.append({\"id\": qa['pq_id'], \"prediction_text\": final_answer})\n",
        "  predicted_answers.append({\"id\": qa['pq_id'], \"prediction_text\": my_normalizer.normalize(final_answer).strip()})\n",
        "  predicted_output.append(my_normalizer.normalize(final_answer).strip())\n",
        "\n",
        "\n",
        "\n",
        "  new_ex = {}\n",
        "  new_ex['id'] = qa[\"pq_id\"]\n",
        "  new_ex['answers'] = {}\n",
        "  new_ex['answers']['answer_start'] = [qa['answers'][0]['start_char']]\n",
        "  # new_ex['answers']['text'] = [qa['answers'][0]['text']]\n",
        "  new_ex['answers']['text'] = [my_normalizer.normalize(qa['answers'][0]['text'])]\n",
        "  theoretical_answers.append(new_ex)\n",
        "  # print(final_answer)\n",
        "  # print(\"***********************\")\n",
        "\n"
      ],
      "metadata": {
        "id": "S7j9i8wugQht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_answers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPCPIwEZmvc5",
        "outputId": "9b8cf902-5c63-4556-8428-55671ba13bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 's2.283', 'prediction_text': 'شهادت را پنهان نکنید'},\n",
              " {'id': 's2.34', 'prediction_text': 'ابلیس'},\n",
              " {'id': 's2.36', 'prediction_text': 'شیطان'},\n",
              " {'id': 's7.22', 'prediction_text': 'شیطان'},\n",
              " {'id': 's7.20', 'prediction_text': 'شیطان'},\n",
              " {'id': 's6.161', 'prediction_text': 'ابراهیم'},\n",
              " {'id': 's41.15', 'prediction_text': 'قوم عاد'},\n",
              " {'id': 's46.21', 'prediction_text': 'قوم عاد'},\n",
              " {'id': 's46.21', 'prediction_text': 'قوم عاد'},\n",
              " {'id': 's51.38', 'prediction_text': 'موسی'},\n",
              " {'id': 's51.38', 'prediction_text': 'فرعون'},\n",
              " {'id': 's54.22', 'prediction_text': 'برای پند گرفتن'},\n",
              " {'id': 's54.18', 'prediction_text': 'عاد'},\n",
              " {'id': 's69.6', 'prediction_text': 'قوم عاد'},\n",
              " {'id': 's69.5', 'prediction_text': 'قوم ثمود'},\n",
              " {'id': 's73.18', 'prediction_text': 'درهم'},\n",
              " {'id': 's73.17', 'prediction_text': 'کودکان'},\n",
              " {'id': 's73.16', 'prediction_text': 'فرعون'},\n",
              " {'id': 's33.33', 'prediction_text': 'شما اهل بیت'},\n",
              " {'id': 's33.53', 'prediction_text': 'هنگامی که دعوت شدید وارد شوید'},\n",
              " {'id': 's33.56', 'prediction_text': 'خدا و فرشتگانش'},\n",
              " {'id': 's2.153', 'prediction_text': 'صابران'},\n",
              " {'id': 's2.151', 'prediction_text': 'ما را'},\n",
              " {'id': 's3.32', 'prediction_text': 'کافران'},\n",
              " {'id': 's3.164', 'prediction_text': ''},\n",
              " {'id': 's3.164', 'prediction_text': 'پاکشان می\\u200cکند'},\n",
              " {'id': 's4.12', 'prediction_text': 'یک ششم'},\n",
              " {'id': 's4.12', 'prediction_text': 'یک سوم'},\n",
              " {'id': 's4.58', 'prediction_text': 'خدا همواره شنوا و بیناست .'},\n",
              " {'id': 's4.58', 'prediction_text': 'صاحبانش'},\n",
              " {'id': 's4.59', 'prediction_text': 'خدا و پیامبر'},\n",
              " {'id': 's4.64', 'prediction_text': '.'},\n",
              " {'id': 's4.83', 'prediction_text': 'شیطان'},\n",
              " {'id': 's5.93', 'prediction_text': 'نیکوکاران'},\n",
              " {'id': 's8.20', 'prediction_text': 'خدا و پیامبرش'},\n",
              " {'id': 's8.24', 'prediction_text': 'خدا و پیامبرش'},\n",
              " {'id': 's9.71', 'prediction_text': ''},\n",
              " {'id': 's24.46', 'prediction_text': 'هر که را بخواهد'},\n",
              " {'id': 's24.52', 'prediction_text': 'خدا و پیامبرش'},\n",
              " {'id': 's24.50', 'prediction_text': 'دل\\u200cهایشان بیماری'},\n",
              " {'id': 's24.62', 'prediction_text': ''},\n",
              " {'id': 's33.37', 'prediction_text': 'فرمان خدا'},\n",
              " {'id': 's47.36', 'prediction_text': 'زندگی دنیا'},\n",
              " {'id': 's48.17', 'prediction_text': 'نابینا و لنگ و بیمار'},\n",
              " {'id': 's49.8', 'prediction_text': 'عطیه و نعمتی'},\n",
              " {'id': 's49.7', 'prediction_text': 'ایمان'},\n",
              " {'id': 's58.13', 'prediction_text': 'خدا و پیامبرش'},\n",
              " {'id': 's58.13', 'prediction_text': 'توبه شما را پذیرفت'},\n",
              " {'id': 's59.6', 'prediction_text': 'اسب و شتری'},\n",
              " {'id': 's64.11', 'prediction_text': 'خدا به همه چیز داناست'},\n",
              " {'id': 's2.256', 'prediction_text': 'شنوا و داناست'},\n",
              " {'id': 's10.108', 'prediction_text': 'خود'},\n",
              " {'id': 's10.108', 'prediction_text': 'حق'},\n",
              " {'id': 's17.12', 'prediction_text': 'روزی و رزقی را از پروردگارتان'},\n",
              " {'id': 's18.31', 'prediction_text': 'جامه\\u200cهایی سبز'},\n",
              " {'id': 's18.31', 'prediction_text': 'طلا'},\n",
              " {'id': 's5.46', 'prediction_text': 'عیسی بن مریم'},\n",
              " {'id': 's2.55', 'prediction_text': '\\u200cای موسی'},\n",
              " {'id': 's2.57', 'prediction_text': 'ابر'},\n",
              " {'id': 's3.169', 'prediction_text': 'پروردگارشان'},\n",
              " {'id': 's7.148', 'prediction_text': 'موسی'},\n",
              " {'id': 's38.34', 'prediction_text': 'سلیمان'},\n",
              " {'id': 's38.34', 'prediction_text': 'گاه'},\n",
              " {'id': 's38.34', 'prediction_text': 'سلیمان'},\n",
              " {'id': 's28.8', 'prediction_text': 'فرعون و هامان'},\n",
              " {'id': 's28.9', 'prediction_text': 'همسر فرعون'},\n",
              " {'id': 's57.12', 'prediction_text': 'مردان و زنان باایمان'},\n",
              " {'id': 's57.13', 'prediction_text': 'مردان و زنان منافق'},\n",
              " {'id': 's57.13', 'prediction_text': 'رحمت'},\n",
              " {'id': 's57.13', 'prediction_text': 'که دارای'},\n",
              " {'id': 's57.12', 'prediction_text': 'از جانب راستش'},\n",
              " {'id': 's11.65', 'prediction_text': 'سه روز'},\n",
              " {'id': 's74.30', 'prediction_text': ''},\n",
              " {'id': 's74.31', 'prediction_text': 'بیماردلان و کافران'},\n",
              " {'id': 's7.150', 'prediction_text': 'ستمکاران'},\n",
              " {'id': 's7.150', 'prediction_text': ''},\n",
              " {'id': 's7.150', 'prediction_text': 'او را به سوی خود می'},\n",
              " {'id': 's7.161', 'prediction_text': 'نیکوکاران'},\n",
              " {'id': 's7.161', 'prediction_text': 'نیکوکاران'},\n",
              " {'id': 's7.162', 'prediction_text': 'ستمکاران'},\n",
              " {'id': 's26.17', 'prediction_text': 'ما'},\n",
              " {'id': 's26.16', 'prediction_text': 'فرعون'},\n",
              " {'id': 's48.12', 'prediction_text': 'پنداشتید پیامبر'},\n",
              " {'id': 's52.28', 'prediction_text': 'نیکوکار و مهربان است .'},\n",
              " {'id': 's7.134', 'prediction_text': 'با تو روانه می'},\n",
              " {'id': 's2.26', 'prediction_text': 'پشه'},\n",
              " {'id': 's2.263', 'prediction_text': 'بخششی است'},\n",
              " {'id': 's2.261', 'prediction_text': 'هفت'},\n",
              " {'id': 's2.182', 'prediction_text': 'انحراف وصیت کننده'},\n",
              " {'id': 's2.180', 'prediction_text': 'پرهیزکاران'},\n",
              " {'id': 's11.70', 'prediction_text': 'قوم لوط'},\n",
              " {'id': 's11.69', 'prediction_text': 'ابراهیم'},\n",
              " {'id': 's2.221', 'prediction_text': 'اتش'},\n",
              " {'id': 's4.84', 'prediction_text': ''},\n",
              " {'id': 's4.84', 'prediction_text': 'کافران'},\n",
              " {'id': 's4.97', 'prediction_text': 'مستضعف بودیم'},\n",
              " {'id': 's4.100', 'prediction_text': ''},\n",
              " {'id': 's4.140', 'prediction_text': 'منافقان و کافران'},\n",
              " {'id': 's5.98', 'prediction_text': 'و'},\n",
              " {'id': 's5.96', 'prediction_text': 'صحرا و بیابان'},\n",
              " {'id': 's8.53', 'prediction_text': 'خدا شنوا و داناست .'},\n",
              " {'id': 's8.50', 'prediction_text': 'کافران'},\n",
              " {'id': 's8.52', 'prediction_text': 'کافر شدند'},\n",
              " {'id': 's46.12', 'prediction_text': 'نیکوکاران'},\n",
              " {'id': 's54.37', 'prediction_text': 'از میهمانان'},\n",
              " {'id': 's25.31', 'prediction_text': 'مجرمان'},\n",
              " {'id': 's25.32', 'prediction_text': 'تا قلب تو'},\n",
              " {'id': 's25.32', 'prediction_text': 'کافران'},\n",
              " {'id': 's25.30', 'prediction_text': 'پیامبر'},\n",
              " {'id': 's29.47', 'prediction_text': 'به'},\n",
              " {'id': 's32.7', 'prediction_text': ''},\n",
              " {'id': 's32.7', 'prediction_text': 'انسان'},\n",
              " {'id': 's34.7', 'prediction_text': ''},\n",
              " {'id': 's34.8', 'prediction_text': ''},\n",
              " {'id': 's35.34', 'prediction_text': 'اندوه را از ما برطرف کرد'},\n",
              " {'id': 's35.30', 'prediction_text': 'فضلش'},\n",
              " {'id': 's35.32', 'prediction_text': ''},\n",
              " {'id': 's35.33', 'prediction_text': 'حریر'},\n",
              " {'id': 's35.33', 'prediction_text': 'طلا و مروارید'},\n",
              " {'id': 's35.33', 'prediction_text': 'حریر'},\n",
              " {'id': 's38.72', 'prediction_text': 'روح خود'},\n",
              " {'id': 's38.78', 'prediction_text': 'تا روز قیامت'},\n",
              " {'id': 's38.86', 'prediction_text': 'من برای ابلاغ دین هیچ پاداشی'},\n",
              " {'id': 's39.23', 'prediction_text': 'هدایت\\u200cکننده ای'},\n",
              " {'id': 's39.24', 'prediction_text': 'صورت'},\n",
              " {'id': 's39.26', 'prediction_text': 'خواری و رسوایی'},\n",
              " {'id': 's39.26', 'prediction_text': 'بزرگ تر'},\n",
              " {'id': 's39.61', 'prediction_text': 'اعمالی که مایه رستگاری شان'},\n",
              " {'id': 's42.5', 'prediction_text': 'فرشتگان'},\n",
              " {'id': 's24.3', 'prediction_text': 'زن زناکار یا مشرک'},\n",
              " {'id': 's12.103', 'prediction_text': '،'},\n",
              " {'id': 's13.2', 'prediction_text': 'خورشید و ماه'},\n",
              " {'id': 's13.4', 'prediction_text': ''},\n",
              " {'id': 's4.105', 'prediction_text': 'داوری'},\n",
              " {'id': 's4.135', 'prediction_text': 'حق'},\n",
              " {'id': 's4.140', 'prediction_text': 'همه منافقان و کافران'},\n",
              " {'id': 's4.142', 'prediction_text': 'منافقان'},\n",
              " {'id': 's4.143', 'prediction_text': 'راهی'},\n",
              " {'id': 's25.47', 'prediction_text': 'برای شما'},\n",
              " {'id': 's40.64', 'prediction_text': 'زمین'},\n",
              " {'id': 's40.64', 'prediction_text': ''},\n",
              " {'id': 's40.64', 'prediction_text': ''},\n",
              " {'id': 's78.10', 'prediction_text': ''},\n",
              " {'id': 's78.11', 'prediction_text': 'و روز را وسیله'},\n",
              " {'id': 's78.12', 'prediction_text': 'هفت'},\n",
              " {'id': 's27.86', 'prediction_text': 'شب'},\n",
              " {'id': 's27.86', 'prediction_text': 'که ما شب را قرار داده ایم'},\n",
              " {'id': 's27.88', 'prediction_text': 'ابر'},\n",
              " {'id': 's33.6', 'prediction_text': 'پیامبر'},\n",
              " {'id': 's51.46', 'prediction_text': 'نوح'},\n",
              " {'id': 's51.40', 'prediction_text': 'به دریا افکندیم'},\n",
              " {'id': 's12.42', 'prediction_text': 'چند سالی'},\n",
              " {'id': 's52.18', 'prediction_text': 'عذاب دوزخ'},\n",
              " {'id': 's18.54', 'prediction_text': 'انسان'},\n",
              " {'id': 's18.56', 'prediction_text': 'تباه کنند !'},\n",
              " {'id': 's30.58', 'prediction_text': 'از هرگونه مثلی زدیم'},\n",
              " {'id': 's30.60', 'prediction_text': 'وعده خدا'},\n",
              " {'id': 's17.8', 'prediction_text': 'کافران'},\n",
              " {'id': 's54.8', 'prediction_text': 'کافران'},\n",
              " {'id': 's75.14', 'prediction_text': 'بیناست .'},\n",
              " {'id': 's75.9', 'prediction_text': 'خورشید و ماه'},\n",
              " {'id': 's19.16', 'prediction_text': 'مریم'},\n",
              " {'id': 's21.33', 'prediction_text': 'شب و روز و خورشید و ماه'},\n",
              " {'id': 's43.51', 'prediction_text': 'مصر'}]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"squad\")\n",
        "\n",
        "a = metric.compute(predictions=predicted_answers, references=theoretical_answers)\n",
        "\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9mzv-0dmTna",
        "outputId": "c459754d-2c9c-4a23-b76f-0fda89d10456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact_match': 42.68292682926829, 'f1': 53.59514130855593}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}